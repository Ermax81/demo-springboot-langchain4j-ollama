# demo-springboot-langchain4j-ollama

How to use Langchain4J with Ollama with simple tests

## Description

This project is a demo of how to use the Langchain4j library with a LLM from Ollama.

## First of all

Mount a local instance of Ollama using docker and retrieve one or several LLMs to use in your project.

To do so, you can use https://github.com/Ermax81/docker-ollama-openwebui.

## Sources

- [How to use to use the LLM for function calling](https://docs.langchain4j.dev/tutorials/tools/)
- [The Berkeley Function Calling Leaderboard](https://gorilla.cs.berkeley.edu/leaderboard.html) (also called Berkeley Tool Calling Leaderboard) evaluates the LLM's ability to call functions (aka tools) accurately. This leaderboard consists of real-world data and will be updated periodically.
- [Ollama](https://ollama.com/)
- [Ollama Mistral LLM tags](https://ollama.com/library/mistral/tags)
- [Ollama Llama3 LLM tags](https://ollama.com/library/llama3/tags)
- [Mistral 7B LLM: Run Locally with Ollama](https://medium.com/@parmarshyamsinh/mistral-7b-llm-run-locally-with-ollama-bf10494be857)


